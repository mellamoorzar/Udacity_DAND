{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifing Fraud from Enron Email and financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Seven/anaconda/envs/DAND/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./tools/')\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import test_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Seven/anaconda/envs/DAND/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Dataset and Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 features in the list.\n"
     ]
    }
   ],
   "source": [
    "# initialize the list\n",
    "features_list = ['poi',\n",
    "                 'salary',\n",
    "                 'bonus',\n",
    "                 'long_term_incentive',\n",
    "                 'deferred_income',\n",
    "                 'deferral_payments',\n",
    "                 'loan_advances', \n",
    "                 'other',\n",
    "                 'expenses', \n",
    "                 'director_fees',\n",
    "                 'total_payments',\n",
    "                 'exercised_stock_options',\n",
    "                 'restricted_stock',\n",
    "                 'restricted_stock_deferred',\n",
    "                 'total_stock_value',\n",
    "                 'to_messages',\n",
    "                 'from_messages',\n",
    "                 'from_this_person_to_poi',\n",
    "                 'from_poi_to_this_person',\n",
    "                 'shared_receipt_with_poi']\n",
    "print \"There are {} features in the list.\".format(len(features_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data exploration and wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 20 columns):\n",
      "poi                          146 non-null float64\n",
      "salary                       95 non-null float64\n",
      "bonus                        82 non-null float64\n",
      "long_term_incentive          66 non-null float64\n",
      "deferred_income              49 non-null float64\n",
      "deferral_payments            39 non-null float64\n",
      "loan_advances                4 non-null float64\n",
      "other                        93 non-null float64\n",
      "expenses                     95 non-null float64\n",
      "director_fees                17 non-null float64\n",
      "total_payments               125 non-null float64\n",
      "exercised_stock_options      102 non-null float64\n",
      "restricted_stock             110 non-null float64\n",
      "restricted_stock_deferred    18 non-null float64\n",
      "total_stock_value            126 non-null float64\n",
      "to_messages                  86 non-null float64\n",
      "from_messages                86 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "shared_receipt_with_poi      86 non-null float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 24.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# load the dictionary containing the dataset\n",
    "with open(\"./data/final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "# transform the dictionary to dataframe\n",
    "df = pd.DataFrame.from_dict(data_dict, orient='index', dtype=np.float)\n",
    "\n",
    "# reorder dataframe\n",
    "df = df[features_list]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of data points: '146' and features: '20'\n",
      "No. of POIs: 18\n",
      "No. of non POIs: 128\n"
     ]
    }
   ],
   "source": [
    "print \"No. of data points: '{}' and features: '{}'\".\\\n",
    "      format(df.shape[0], df.shape[1])\n",
    "print \"No. of POIs: {}\".format(len(df[df['poi'] == 1]))\n",
    "print \"No. of non POIs: {}\".format(len(df[df['poi'] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 features by missing values:\n",
      "loan_advances                142\n",
      "director_fees                129\n",
      "restricted_stock_deferred    128\n",
      "deferral_payments            107\n",
      "deferred_income               97\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# missing values by feature\n",
    "df = df.replace('NaN', np.nan)\n",
    "print \"Top 5 features by missing values:\\n\",\\\n",
    "      df.isnull().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 records by missing values::\n",
      "LOCKHART EUGENE E                19\n",
      "GRAMM WENDY L                    17\n",
      "WROBEL BRUCE                     17\n",
      "WODRASKA JOHN                    17\n",
      "THE TRAVEL AGENCY IN THE PARK    17\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# missing values by record\n",
    "nan_value_row = df.isnull().sum(axis=1)\n",
    "print \"Top 5 records by missing values::\\n\",\\\n",
    "      nan_value_row.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poi                          0.0\n",
       "salary                       NaN\n",
       "bonus                        NaN\n",
       "long_term_incentive          NaN\n",
       "deferred_income              NaN\n",
       "deferral_payments            NaN\n",
       "loan_advances                NaN\n",
       "other                        NaN\n",
       "expenses                     NaN\n",
       "director_fees                NaN\n",
       "total_payments               NaN\n",
       "exercised_stock_options      NaN\n",
       "restricted_stock             NaN\n",
       "restricted_stock_deferred    NaN\n",
       "total_stock_value            NaN\n",
       "to_messages                  NaN\n",
       "from_messages                NaN\n",
       "from_this_person_to_poi      NaN\n",
       "from_poi_to_this_person      NaN\n",
       "shared_receipt_with_poi      NaN\n",
       "Name: LOCKHART EUGENE E, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ix['LOCKHART EUGENE E']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: There is no useful information in data point `LOCKHART EUGENE E`. I'm going to remove it from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poi                               0.0\n",
       "salary                            NaN\n",
       "bonus                             NaN\n",
       "long_term_incentive               NaN\n",
       "deferred_income                   NaN\n",
       "deferral_payments                 NaN\n",
       "loan_advances                     NaN\n",
       "other                        362096.0\n",
       "expenses                          NaN\n",
       "director_fees                     NaN\n",
       "total_payments               362096.0\n",
       "exercised_stock_options           NaN\n",
       "restricted_stock                  NaN\n",
       "restricted_stock_deferred         NaN\n",
       "total_stock_value                 NaN\n",
       "to_messages                       NaN\n",
       "from_messages                     NaN\n",
       "from_this_person_to_poi           NaN\n",
       "from_poi_to_this_person           NaN\n",
       "shared_receipt_with_poi           NaN\n",
       "Name: THE TRAVEL AGENCY IN THE PARK, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ix['THE TRAVEL AGENCY IN THE PARK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: `THE TRAVEL AGENCY IN THE PARK` is clearly not a person and is not helpful to identify a POI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove data points: 'LOCKHART EUGENE E' & 'THE TRAVEL AGENCY IN THE PARK'\n",
    "df = df.drop(['LOCKHART EUGENE E', 'THE TRAVEL AGENCY IN THE PARK'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill na for email features \n",
    "email_features = ['to_messages',\n",
    "                  'from_messages',\n",
    "                  'from_this_person_to_poi',\n",
    "                  'from_poi_to_this_person',\n",
    "                  'shared_receipt_with_poi']\n",
    "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "\n",
    "df.loc[df[df.poi == 1].index, email_features] =\\\n",
    "imp.fit_transform(df[email_features][df.poi == 1])\n",
    "\n",
    "df.loc[df[df.poi == 0].index, email_features] =\\\n",
    "imp.fit_transform(df[email_features][df.poi == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill na with 0 for financial features\n",
    "df.ix[:,:15] = df.ix[:,:15].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### data errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records with payment_features error:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-102500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>102500.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44093.0</td>\n",
       "      <td>-44093.0</td>\n",
       "      <td>944.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>2604490.0</td>\n",
       "      <td>-2604490.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>463.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  poi  salary  bonus  long_term_incentive  deferred_income  \\\n",
       "BELFER ROBERT     0.0     0.0    0.0                  0.0              0.0   \n",
       "BHATNAGAR SANJAY  0.0     0.0    0.0                  0.0              0.0   \n",
       "\n",
       "                  deferral_payments  loan_advances     other  expenses  \\\n",
       "BELFER ROBERT             -102500.0            0.0       0.0       0.0   \n",
       "BHATNAGAR SANJAY                0.0            0.0  137864.0       0.0   \n",
       "\n",
       "                  director_fees  total_payments  exercised_stock_options  \\\n",
       "BELFER ROBERT            3285.0        102500.0                   3285.0   \n",
       "BHATNAGAR SANJAY       137864.0      15456290.0                2604490.0   \n",
       "\n",
       "                  restricted_stock  restricted_stock_deferred  \\\n",
       "BELFER ROBERT                  0.0                    44093.0   \n",
       "BHATNAGAR SANJAY        -2604490.0                 15456290.0   \n",
       "\n",
       "                  total_stock_value  to_messages  from_messages  \\\n",
       "BELFER ROBERT              -44093.0        944.0           41.0   \n",
       "BHATNAGAR SANJAY                0.0        523.0           29.0   \n",
       "\n",
       "                  from_this_person_to_poi  from_poi_to_this_person  \\\n",
       "BELFER ROBERT                         6.0                     26.5   \n",
       "BHATNAGAR SANJAY                      1.0                      0.0   \n",
       "\n",
       "                  shared_receipt_with_poi  \n",
       "BELFER ROBERT                       594.0  \n",
       "BHATNAGAR SANJAY                    463.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate data by comparing the sum of all payment features with 'total_payments'\n",
    "payment_features = ['salary',\n",
    "                    'bonus',\n",
    "                    'long_term_incentive',\n",
    "                    'deferred_income',\n",
    "                    'deferral_payments',\n",
    "                    'loan_advances',\n",
    "                    'other',\n",
    "                    'expenses',\n",
    "                    'director_fees']\n",
    "print \"Records with payment_features error:\"\n",
    "df[df[payment_features].sum(axis=1) != df.total_payments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records with stock_features error:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-102500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>102500.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44093.0</td>\n",
       "      <td>-44093.0</td>\n",
       "      <td>944.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>2604490.0</td>\n",
       "      <td>-2604490.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>463.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  poi  salary  bonus  long_term_incentive  deferred_income  \\\n",
       "BELFER ROBERT     0.0     0.0    0.0                  0.0              0.0   \n",
       "BHATNAGAR SANJAY  0.0     0.0    0.0                  0.0              0.0   \n",
       "\n",
       "                  deferral_payments  loan_advances     other  expenses  \\\n",
       "BELFER ROBERT             -102500.0            0.0       0.0       0.0   \n",
       "BHATNAGAR SANJAY                0.0            0.0  137864.0       0.0   \n",
       "\n",
       "                  director_fees  total_payments  exercised_stock_options  \\\n",
       "BELFER ROBERT            3285.0        102500.0                   3285.0   \n",
       "BHATNAGAR SANJAY       137864.0      15456290.0                2604490.0   \n",
       "\n",
       "                  restricted_stock  restricted_stock_deferred  \\\n",
       "BELFER ROBERT                  0.0                    44093.0   \n",
       "BHATNAGAR SANJAY        -2604490.0                 15456290.0   \n",
       "\n",
       "                  total_stock_value  to_messages  from_messages  \\\n",
       "BELFER ROBERT              -44093.0        944.0           41.0   \n",
       "BHATNAGAR SANJAY                0.0        523.0           29.0   \n",
       "\n",
       "                  from_this_person_to_poi  from_poi_to_this_person  \\\n",
       "BELFER ROBERT                         6.0                     26.5   \n",
       "BHATNAGAR SANJAY                      1.0                      0.0   \n",
       "\n",
       "                  shared_receipt_with_poi  \n",
       "BELFER ROBERT                       594.0  \n",
       "BHATNAGAR SANJAY                    463.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate data by comparing the sum of all stock features with 'total_stock_value'\n",
    "stock_features = ['exercised_stock_options',\n",
    "                  'restricted_stock',\n",
    "                  'restricted_stock_deferred']\n",
    "print \"Records with stock_features error:\"\n",
    "df[df[stock_features].sum(axis=1) != df.total_stock_value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the numbers were filled in the wrong entry. We'll try to fix `BELFER ROBERT` by shifting them 1 column to the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of records with payment_features error:  1\n",
      "No. of records with stock_features error:  1\n"
     ]
    }
   ],
   "source": [
    "# payment_features\n",
    "df.ix['BELFER ROBERT','deferred_income'] = -102500.0\n",
    "df.ix['BELFER ROBERT','deferral_payments'] = 0.0\n",
    "df.ix['BELFER ROBERT','expenses'] = 3285.0\n",
    "df.ix['BELFER ROBERT','director_fees'] = 102500.0\n",
    "df.ix['BELFER ROBERT','total_payments'] = 3285.0\n",
    "# stock_features\n",
    "df.ix['BELFER ROBERT','exercised_stock_options'] = 0.0\n",
    "df.ix['BELFER ROBERT','restricted_stock'] = 44093.0\n",
    "df.ix['BELFER ROBERT','restricted_stock_deferred'] = -44093.0\n",
    "df.ix['BELFER ROBERT','total_stock_value'] = 0.0\n",
    "\n",
    "print \"No. of records with payment_features error: \",\\\n",
    "      len(df[df[payment_features].sum(axis=1) != df.total_payments])\n",
    "print \"No. of records with stock_features error: \",\\\n",
    "      len(df[df[payment_features].sum(axis=1) != df.total_payments])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works. Let's fix `BHATNAGAR SANJAY` by shifting numbers 1 column to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of records with payment_features error:  0\n",
      "No. of records with stock_features error:  0\n"
     ]
    }
   ],
   "source": [
    "# payment_features\n",
    "df.ix['BHATNAGAR SANJAY','other'] = 0.0\n",
    "df.ix['BHATNAGAR SANJAY','expenses'] = 137864.0\n",
    "df.ix['BHATNAGAR SANJAY','director_fees'] = 0.0\n",
    "df.ix['BHATNAGAR SANJAY','total_payments'] = 137864.0\n",
    "# stock_features\n",
    "df.ix['BHATNAGAR SANJAY','exercised_stock_options'] = 15456290.0\n",
    "df.ix['BHATNAGAR SANJAY','restricted_stock'] = 2604490.0\n",
    "df.ix['BHATNAGAR SANJAY','restricted_stock_deferred'] = -2604490.0\n",
    "df.ix['BHATNAGAR SANJAY','total_stock_value'] = 15456290.0\n",
    "\n",
    "print \"No. of records with payment_features error: \",\\\n",
    "      len(df[df[payment_features].sum(axis=1) != df.total_payments])\n",
    "print \"No. of records with stock_features error: \",\\\n",
    "      len(df[df[payment_features].sum(axis=1) != df.total_payments])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. of outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAY KENNETH L</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FREVERT MARK A</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKILLING JEFFREY K</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHALLEY LAWRENCE G</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    No. of outliers\n",
       "LAY KENNETH L                    13\n",
       "FREVERT MARK A                   13\n",
       "SKILLING JEFFREY K               12\n",
       "WHALLEY LAWRENCE G               12\n",
       "TOTAL                            12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort data points by sum of outlier variables\n",
    "outliers = df.quantile(.5) + 1.5 * (df.quantile(.75) - df.quantile(.25))\n",
    "pd.DataFrame((df[1:] > outliers[1:]).\\\n",
    "             sum(axis=1), columns=['No. of outliers']).\\\n",
    "             sort_values('No. of outliers', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results reflect multiple records with values outside of the quantile boundaries. Based on the facts of the case, this made sense for some of the finance data points and key individuals within Enron. Therefore, the records for actual people will not be removed. However, the TOTAL record is a spreadsheet calculation quirk from the finance data. So this outlier will be removed from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove outliers: 'TOTAL'\n",
    "df = df.drop('TOTAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Feature Selection/Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. financial_total\n",
    "2. fraction_from_poi\n",
    "3. fraction_to_poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LAY KENNETH L         152669871.0\n",
       "SKILLING JEFFREY K     34776388.0\n",
       "FREVERT MARK A         31874715.0\n",
       "HIRKO JOSEPH           30857157.0\n",
       "PAI LOU L              26941313.0\n",
       "Name: financial_total, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 'financial_total' feature\n",
    "df['financial_total'] = df['total_payments'] + df['total_stock_value']\n",
    "df.financial_total.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DONAHUE JR JEFFREY M    0.217341\n",
       "DEFFNER JOSEPH M        0.161064\n",
       "COLWELL WESLEY          0.136519\n",
       "REDMOND BRIAN L         0.122083\n",
       "DIETRICH JANET R        0.118585\n",
       "Name: fraction_from_poi, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 'fraction_from_poi' feature\n",
    "df['fraction_from_poi'] = df['from_poi_to_this_person']/df['to_messages']\n",
    "# clean 'inf' values caused by zero value of 'to_messages'\n",
    "df = df.replace('inf', 0)\n",
    "df.fraction_from_poi.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HUMPHREY GENE E       1.000000\n",
       "SHERRICK JEFFREY B    0.720000\n",
       "HANNON KEVIN P        0.656250\n",
       "GARLAND C KEVIN       0.613636\n",
       "RIEKER PAULA H        0.585366\n",
       "Name: fraction_to_poi, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 'fraction_to_poi' feature\n",
    "df['fraction_to_poi'] = df['from_this_person_to_poi']/df['from_messages']\n",
    "# clean 'inf' values caused by zero value of 'from_messages'\n",
    "df = df.replace('inf', 0)\n",
    "df.fraction_to_poi.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# store dataframe with new features_list\n",
    "features_list = features_list + ['financial_total', 'fraction_from_poi', 'fraction_to_poi']\n",
    "df = df[features_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### intelligently select features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fraction_to_poi', 0.34628571428571447]\n",
      "['shared_receipt_with_poi', 0.22013095238095232]\n",
      "['expenses', 0.16820105820105813]\n",
      "['other', 0.15642989417989422]\n",
      "['fraction_from_poi', 0.06128571428571427]\n",
      "['deferral_payments', 0.047666666666666663]\n"
     ]
    }
   ],
   "source": [
    "# get new feature list ccording to feature importances with decision tree\n",
    "dt = DecisionTreeClassifier(random_state = 42)\n",
    "dt.fit(df.ix[:,1:], df.ix[:,:1])\n",
    "\n",
    "features_importance = []\n",
    "for i in range(len(dt.feature_importances_)):\n",
    "    if dt.feature_importances_[i] > 0:\n",
    "        features_importance.append([df.columns[i+1], dt.feature_importances_[i]])\n",
    "features_importance.sort(key=lambda x: x[1], reverse = True)\n",
    "for f_i in features_importance:\n",
    "    print f_i\n",
    "features_list = [x[0] for x in features_importance]\n",
    "features_list.insert(0, 'poi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poi',\n",
       " 'fraction_to_poi',\n",
       " 'shared_receipt_with_poi',\n",
       " 'expenses',\n",
       " 'other',\n",
       " 'fraction_from_poi',\n",
       " 'deferral_payments']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract features and labels from dataset for local testing\n",
    "my_dataset = df.to_dict('index')\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick and Tune an Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### try a varity of classifiers\n",
    "\n",
    "* Naive Baye\n",
    "* Decision Tree\n",
    "* Ada Boost\n",
    "* Random Forest\n",
    "* K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', GaussianNB(priors=None))])\n",
      "\tAccuracy: 0.79267\tPrecision: 0.12551\tRecall: 0.09300\tF1: 0.10684\tF2: 0.09808\n",
      "\tTotal predictions: 15000\tTrue positives:  186\tFalse positives: 1296\tFalse negatives: 1814\tTrue negatives: 11704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try Naive Bayes\n",
    "nb = GaussianNB()\n",
    "pipe_nb = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                          ('pca', PCA()),\n",
    "                          ('clf', nb)])\n",
    "\n",
    "test_classifier(pipe_nb, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "      ...        min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'))])\n",
      "\tAccuracy: 0.83360\tPrecision: 0.38302\tRecall: 0.40600\tF1: 0.39417\tF2: 0.40119\n",
      "\tTotal predictions: 15000\tTrue positives:  812\tFalse positives: 1308\tFalse negatives: 1188\tTrue negatives: 11692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try Decision Tree\n",
    "dt = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "pipe_dt = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                          ('pca', PCA()),\n",
    "                          ('clf', dt)])\n",
    "\n",
    "test_classifier(pipe_dt, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifi...e=42,\n",
      "            splitter='best'),\n",
      "          learning_rate=1.0, n_estimators=50, random_state=42))])\n",
      "\tAccuracy: 0.83493\tPrecision: 0.38763\tRecall: 0.41050\tF1: 0.39874\tF2: 0.40571\n",
      "\tTotal predictions: 15000\tTrue positives:  821\tFalse positives: 1297\tFalse negatives: 1179\tTrue negatives: 11703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try Ada Boost\n",
    "ada = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(criterion='entropy',\n",
    "                                          random_state=42),\n",
    "    random_state=42)\n",
    "pipe_ada = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                           ('pca', PCA()),\n",
    "                           ('clf', ada)])\n",
    "\n",
    "test_classifier(pipe_ada, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "         ...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\tAccuracy: 0.87207\tPrecision: 0.53990\tRecall: 0.27400\tF1: 0.36352\tF2: 0.30394\n",
      "\tTotal predictions: 15000\tTrue positives:  548\tFalse positives:  467\tFalse negatives: 1452\tTrue negatives: 12533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "pipe_rf = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                          ('pca', PCA()),\n",
    "                          ('clf', rf)])\n",
    "\n",
    "test_classifier(pipe_rf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=42, tol=0.0001, verbose=0))])\n",
      "\tAccuracy: 0.75233\tPrecision: 0.16699\tRecall: 0.21500\tF1: 0.18798\tF2: 0.20331\n",
      "\tTotal predictions: 15000\tTrue positives:  430\tFalse positives: 2145\tFalse negatives: 1570\tTrue negatives: 10855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try K-mean\n",
    "km = KMeans(n_clusters=2, random_state=42)\n",
    "pipe_km = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                          ('pca', PCA()),\n",
    "                          ('clf', km)])\n",
    "\n",
    "test_classifier(pipe_km, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=3, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best')\n",
      "\tAccuracy: 0.90920\tPrecision: 0.68002\tRecall: 0.60250\tF1: 0.63892\tF2: 0.61656\n",
      "\tTotal predictions: 15000\tTrue positives: 1205\tFalse positives:  567\tFalse negatives:  795\tTrue negatives: 12433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# create a grid search\n",
    "grid = {\n",
    "    'criterion': ('gini', 'entropy'),\n",
    "    'min_samples_split': range(2, 7),\n",
    "    'min_samples_leaf': range(1, 7)\n",
    "}\n",
    "search = GridSearchCV(estimator=dt, param_grid=grid,\n",
    "                      scoring=make_scorer(f1_score), cv=3)\n",
    "\n",
    "# fit the search\n",
    "search.fit(features, labels)\n",
    "\n",
    "# assign clf with best estimator\n",
    "clf = search.best_estimator_\n",
    "\n",
    "# use included tester function to assess performance using cross validation\n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [ENRON - The Smartest Guys in the Room](https://www.youtube.com/watch?v=dbg5J_AjIto)\n",
    "* [A look at those involved in the Enron scandal](http://usatoday30.usatoday.com/money/industries/energy/2005-12-28-enron-participants_x.htm)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
